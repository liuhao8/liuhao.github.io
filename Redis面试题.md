> Redis为什么快？

1.纯内存访问

2.单线程避免上下文切换

3.渐进式ReHash

产生哈希碰撞需要扩容时，进行rehash操作，多个任务分多次进行，就是渐进式

4.缓存时间戳

redis单线程获取系统时间相对耗时，使用毫秒级定时任务进行系统时间的刷新



> Redis的应用场景

1.缓存（最常用，得益于优秀的读写速度，支持高并发）

2.计数器

3.分布式会话（用于共享session）

4.排行榜

5.最新列表

6.分布式锁

7.消息队列（基于列表实现）

8.UV（基于HyperLogLog实现）



> Redis6.0之前为什么一直不使用多线程

1.使用Redis、CPU不是瓶颈，受制于 内存、网络

2.Pipeline（命令批量执行）每秒100万个请求

3.单线程，避免了多线程的一些维护成本

4.避免了（线程切换、加锁解锁、死锁等问题）

5.渐进式Rehash进一步提高速度

因此，对于一般企业来说，Redis足够支持高强度的访问



> Redis6.0为什么要引入多线程

1.从内存中读写数据的相应时间为100纳秒，对于比较小的数据包，8W-10W QPS是极限值

2.大的公司，需要更大的QPS，Redis基于IO的多线程（内部执行命令还是单线程）提高了并发量。

3.为什么不采用分布式架构——有很大的缺点

服务数量多，维护成本很高

Redis命令不适用于数据分区

即使数据分区了也无法解决热点读/写的问题

数据倾斜、重新分配、扩容、缩容，会更加复杂



> Redis有哪些高级功能

1.慢查询（需要配置开启），用于记录超过预设阈值的命令

2.Pipeline（批量管道）

![image-20231123201847185](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231123201847185.png)

主要的目的是为了节省RTT（往返时间）

3.watch

有些应用场景需要在事务之前，确保事务中的key没有被其他客户端修改过，才执行事务，否则不执行（乐观锁）

Redis的弱事务性

语法没问题，但是运行时出错，redis弱事务不会回滚

4.Lua

![image-20231123202224038](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231123202224038.png)



> 为什么要用Redis

1.高性能

由于DB层的数据读取是通过磁盘的，使用Redis用做缓存层，可以使数据读取效率千百倍提升

缓存同步的两种情形：

⑴应用启动时，全量同步

⑵数据变化时，增量更新

2.高并发

通过缓存的方式作为中间层，一个Redis可以抗住10W级并发量的访问



> Redis与memcached相对有哪些优势

|            | Redis                                                        |       Memcached        |
| :--------: | ------------------------------------------------------------ | :--------------------: |
|  整体类型  | 支持内存、非关系型数据库                                     | 支持内存，键值对数据库 |
|  数据类型  | 很多，常用5种 String、List、Set、Zset、Hash                  | 2种 文本型和二进制类型 |
|  操作类型  | 1、单个操作 2、批量操作 3、事务支持（弱事务、结合Lua） 4、每个类型不同的CURD、 |  Curd 和 其他少量命令  |
|  附加功能  | 1、发布\订阅模式 2、主从模式 3、序列化支持 4、lua脚本        |     多线程服务支持     |
| 网络IO模型 | 执行命令——单线程  网络操作——多线程                           |   多线程，非阻塞的IO   |
|   持久化   | RDB AOF                                                      |           无           |

总体来看，memcached在多线程模式有自己独特的优势，其他场景无疑是Redis更适合



> 怎么理解Redis中事务？

multi开始事务

sadd添加队列

exec提交事务

discard回滚 

只能针对语法错误，无法识别运行时操作，运行时错误无法回滚

![image-20231124183304319](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231124183304319.png)



> Redis的过期策略以及内存淘汰机制

redis 采用的是定期删除+惰性删除策略。 

为什么不用定时删除策略? 定时删除,用一个 定时器来负责监视 key,过期则自动删除。虽然内存及时释放，但是十分消耗 CPU 资源。在 大并发请求下，CPU 要将时间应用在处理请求，而不是删除 key,因此没有采用这一策略. 

定 期删除+惰性删除是如何工作的呢? 定期删除，redis 默认每个 100ms 检查，是否有过期的 key,有过期 key 则删除。需要说明的是，redis 不是每个 100ms 将所有的 key 检查一次，而是 随机抽取进行检查(如果每隔 100ms,全部 key 进行检查，redis 岂不是卡死)。因此，如果只采 用定期删除策略，会导致很多 key 到时间没有删除。 

定期删除随机抽取一批需要删除的比例超过四分之一次，会重复删除的策略。这种情况在面对大规模key失效时，会造成服务器的卡顿。

于是，惰性删除派上用场。也就是说 在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？ 如果过期了此时就会删除 



> 什么是缓存穿透，如何避免？

缓存穿透：指查询一个一定不存在的数据，如果从存储层查不到数据则不写入缓存，这 将导致这个不存在的数据每次请求都要到 DB 去查询，可能导致 DB 挂掉。

解决方案：

1.查询返回的数据为空，仍把这个空结果进行缓存，但过期时间会比较短； 

2.布隆过滤器：将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的 数据会被这个 bitmap 拦截掉，从而避免了对 DB 的查询



> 什么是缓存雪崩，如何避免？

缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全 部转发到 DB，DB 瞬时压力过重雪崩。

与缓存击穿的区别：雪崩是很多 key，击穿是某一 个 key 缓存。

 解决方案：将缓存失效时间分散开，比如可以在原有的失效时间基础上增加一个随机值， 比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效 的事件。



> 使用Redis如何设计分布式锁？

1.使用SETNX 来加锁 （无key才会执行，有key不生效）

2.设置锁的超时时间，一定程度上防止死锁

3.加入看门狗（守护）线程，来监听为锁续命



> 怎么使用Redis实现消息队列？

基于 List 的 LPUSH+BRPOP 的实现 

足够简单，消费消息延迟几乎为零，但是需要处理空闲连接的问题。 如果线程一直阻塞在那里，Redis 客户端的连接就成了闲置连接，闲置过久，服务器一 般会主动断开连接，减少闲置资源占用，这个时候 blpop 和 brpop 或抛出异常，所以在编写 客户端消费者的时候要小心，如果捕获到异常，还有重试。 

其他缺点包括： 

做消费者确认 ACK 麻烦，不能保证消费者消费消息后是否成功处理的问题（宕机或处 理异常等），通常需要维护一个 Pending 列表，保证消息处理确认；不能做广播模式，如 pub/sub，消息发布/订阅模型；不能重复消费，一旦消费就会被删除；不支持分组消费。 

基于 Sorted-Set 的实现 

多用来实现延迟队列，当然也可以实现有序的普通的消息队列，但是消费者无法阻塞的 获取消息，只能轮询，不允许重复消息。 

PUB/SUB，订阅/发布模式 

优点： 

典型的广播模式，一个消息可以发布到多个消费者；多信道订阅，消费者可以同时订阅 多个信道，从而接收多类消息；消息即时发送，消息不用等待消费者读取，消费者会自动接 收到信道发布的消息。

缺点： 

消息一旦发布，不能接收。换句话就是发布时若客户端不在线，则消息丢失，不能寻回； 不能保证每个消费者接收的时间是一致的；若消费者客户端出现消息积压，到一定程度，会 被强制断开，导致消息意外丢失。通常发生在消息的生产远大于消费速度时；可见，Pub/Sub 模式不适合做消息存储，消息积压类的业务，而是擅长处理广播，即时通讯，即时反馈的业 务。 

基于 Stream 类型的实现 

基本上已经有了一个消息中间件的雏形，可以考虑在生产过程中使用。

消息队列的问题：

![image-20231128164943460](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231128164943460.png)

![image-20231128165017799](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231128165017799.png)

![image-20231128165123961](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231128165123961.png)



> 什么是bigKey？会有什么影响？

bigkey 是指 key 对应的 value 所占的内存空间比较大，例如一个字符串类型的 value 可 以最大存到 512MB，一个列表类型的 value 最多可以存储 23-1 个元素。 如果按照数据结构来细分的话，一般分为字符串类型 bigkey 和非字符串类型 bigkey。 

字符串类型：

体现在单个 value 值很大，一般认为超过 10KB 就是 bigkey，但这个值和 具体的 OPS 相关。 

非字符串类型：

哈希、列表、集合、有序集合,体现在元素个数过多。 bigkey 无论是空间复杂度和时间复杂度都不太友好，下面我们将介绍它的危害。 

bigkey 的危害 bigkey 的危害体现在三个方面: 

1、内存空间不均匀.(平衡):例如在 Redis Cluster 中，bigkey 会造成节点的内存空间使用 不均匀。 

2、超时阻塞:由于 Redis 单线程的特性，操作 bigkey 比较耗时，也就意味着阻塞 Redis 可能性增大。 

3、网络拥塞:每次获取 bigkey 产生的网络流量较大 假设一个 bigkey 为 1MB，每秒访问量为 1000，那么每秒产生 1000MB 的流量,对于普通 的千兆网卡(按照字节算是 128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用 单机多实例的方式来部署,也就是说一个 bigkey 可能会对其他实例造成影响,其后果不堪设想。



解决方式？ 简单做拆分，大容量拆成N个，用结尾的序号确立好顺序即可。

查询bigkey命令 redis -cli --bigkeys



> Redis如何解决key冲突？

1.业务隔离



不同的业务使用不同的redis库

2.命名规范话

系统+业务+功能

3.分布式锁确保唯一



> 怎么提高缓存命中率？

1.提前加载

2.增加缓存的存储空间，提高缓存的数据、提高命中3率

3.调整缓存的存储类型

4.提升缓存的更新频次（设立定时任务定刷、利用mq生产消费实现实时更新）



> Redis持久化方式有哪些？有什么区别？

1、RDB（Redis Data Base）

把内存快照记录到硬盘。内存快照是指内存中的数据在某一个时刻的状态记录

可能会导致数据丢失问题

![image-20231211104551495](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231211104551495.png)

2、AOF（append only file）

以日志的形式每次记录命令，是为了保证数据的实时性，效率较差。

3.混合

优先以RDB恢复，断层处用AOF恢复。



> 为什么Redis需要把所有数据放到内存中？

Redis 为了达到最快的读写速度,将数据都读到内存中,并通过异步的方式将数据写入磁 盘,所以 Redis 具有快速和数据持久化的特征。如果不将数据放在内存中,磁盘 I/O 速度为严重 影响 Redis 的性能。



> 如何保证缓存与数据库双写时的数据一致性？

第一种方案：采用延时双删策略 具体的步骤就是： 先删除缓存； 再写数据库； 休眠 500 毫秒； 再次删除缓存。

第二种方案：异步更新缓存(基于订阅 binlog 的同步机制) 技术整体思路： MySQL binlog 增量订阅消费+消息队列+增量数据更新到 redis



> Redis集群方案应该怎么做？

1. Redis Sentinel 体量较小时，选择 Redis Sentinel，单主 Redis 足以支撑业务。 

2. Redis ClusterRedis 官方提供的集群化方案，体量较大时，选择 Redis Cluster，通过分 片，使用更多内存。 
3. TwemproxTwemprox 是 Twtter 开源的一个 Redis 和 Memcached 代理服务器，主要 用于管理 Redis 和 Memcached 集群，减少与 Cache 服务器直接连接的数量。 
4. CodisCodis 是一个代理中间件，当客户端向 Codis 发送指令时，Codis 负责将指令转发 到后面的 Redis 来执行，并将结果返回给客户端。一个 Codis 实例可以连接多个 Redis 实例， 也可以启动多个 Codis 实例来支撑，每个 Codis 节点都是对等的，这样可以增加整体的 QPS 需求，还能起到容灾功能。 
5. 客户端分片在 Redis Cluster 还没出现之前使用较多，现在基本很少热你使用了，在业 务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 Key 进行 hash 计算，然后 去对应的 Redis 实例操作数据。这种方式对 hash 层代码要求比较高，考虑部分包括，节点 失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。



> Redis集群方案什么情况下会导致整个集群不可用？

1.访问一个Master和Slave节点都挂了的时候，cluster-require-full-coverage = yes，会报槽无法获取

2.集群主库半数宕机，fail掉一个主需要一半以上的主都投票

3.Master节点个数小于三个，或者集群的可用节点个数为偶数，fail的选举机制自动主从切换过程可能会不能正常工作



> 说一说Redis哈希槽的概念

节点取余分区：简单易实现，新增节点时会打算顺序，进行全部rehash

一致性哈希分区：抽象成哈希环，从环上找节点，缺点是新增节点会导致一部分数据不能名字，解决方案是查最近的两个node

Redis预分区：虚拟分区+代理请求

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201003195043513.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTgzMjQy,size_16,color_FFFFFF,t_70#pic_center)

slot：称为哈希槽 Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时， redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映 射到不同的节点。 

使用哈希槽的好处就在于可以方便的添加或移除节点。 

当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了； 

当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了



> Redis集群会有写操作丢失吗？为什么？

以下情况可能导致写操作丢失： 

过期 key 被清理 

最大内存不足，导致 Redis 自动清理部分 key 以节省空间 

主库故障后自动重启，从库自动同步 

单独的主备方案，网络不稳定触发哨兵的自动切换主从节点，切换期间会有数据丢失



> Redis常见性能问题和解决方案有哪些？

持久化可能会产生性能问题 主从 主不做持久化，从做持久化

![image-20231212112931940](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231212112931940.png)

![image-20231212112949710](C:\Users\12628\AppData\Roaming\Typora\typora-user-images\image-20231212112949710.png)



> 热点数据和冷数据是什么

对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存， 而且价值不 大。频繁修改的数据，看情况考虑使用缓存 对于上面两个例子，寿星列表、导 航信息都存在一个特点，就是信息修改频率不高，读取通常非常高的 场景。 

对于热点数据，比如我们的某 IM 产品，生日祝福模块，当天的寿星列表，缓存以后可 能读取数十万次。 再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万 次。



> 什么情况下可能会导致Redis阻塞？

1、客户端大命令的阻塞 keys* Hgetall

2、Bigkey删除时的阻塞

3、清空库时的阻塞

4、AOF日志同步写时会阻塞 记录AOF日志，存在大量的写操作时会阻塞

5、从库 加载RDB文件



> 什么时候选择Redis，什么时候选择Memcached？

实际业务分析 如果业务中更加侧重性能的⾼效性，对持久化要求不⾼，那么应该优先选择 Memcached。 如果业务中对持久化有需求或者对数据涉及到存储、排序等一系列复杂的操作，比如业 务中有排⾏榜类应⽤、社交关系存储、数据排重、实时配置等功能，那么应该优先选择 Redis



> Redis过期策略有哪些？LRU算法是什么？

缓存淘汰算法

1.noeviction:返回错误当内存限制达到，并且客户端尝试执行会让更多内存被使用的命 令。

2.allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。

3.volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的 数据有空间存放。

4.allkeys-random: 回收随机的键使得新添加的数据有空间存放。 

5.volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的 键。 6.volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添 加的数据有空间存放。



Lru算法？

长链表用来存储所有元素，当元素被访问时将其提到最前，内存超出时删除最尾部的元素，也就是最不经常访问的。

Redis的近似Lru算法？

不使用Lru算法是因为它要使用大量的内存，Redis为了效率需要对其进行改造。

Redis对每个key增加了一个额外的字段，记录最后一次被访问的时间戳。然后随机采样5个key，淘汰其最旧的，如果还是超出，就重复步骤。

3.0版本之后，新算法维护了一个侯选池



Lfu算法？

优先考虑近期访问频次，频次越多的越不容易被淘汰
